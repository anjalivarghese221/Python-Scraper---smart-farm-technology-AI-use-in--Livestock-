#  Smart Farm Technology & AI in Livestock Analysis

Python-based social media scraper and sentiment analyzer for smart farming technology and AI use in livestock management.

##  Overview

**4-Step Analysis Pipeline:**
1. **Scraper** - Collect Reddit posts about smart farming and livestock AI
2. **Sentiment Analysis** - Train and apply ML model to classify opinions
3. **Network Analysis** - Extract keywords and map co-occurrence networks
4. **Final Analysis** - Comprehensive sentiment report with visualizations

##  Features

### Step 1: Reddit Scraping & Text Cleaning
- Scrapes farming/agriculture subreddits using public JSON API
- 9-step text cleaning pipeline (deduplication, stop words, lemmatization)
- Generates cleaned dataset for analysis

### Step 2: Sentiment Model
- Trains Logistic Regression classifier with 150 labeled examples
- Classifies posts as positive, negative, or neutral
- Saves trained model for reuse

### Step 3: Network Analysis
- Extracts meaningful keywords (filters 100+ stop words)
- Builds co-occurrence network (keywords appearing together)
- Detects topic communities using Louvain algorithm
- Generates 8 network visualizations

### Step 4: Final Sentiment Analysis
- Comprehensive sentiment report by subreddit
- Statistical analysis and visualizations
- 4-panel sentiment overview chart

##  Getting Started

### Installation
```bash
pip3 install -r requirements.txt
```

### Usage

**Run all 4 steps:**
```bash
python3 main.py                      # Step 1: Scraping & cleaning
python3 sentiment_model.py           # Step 2a: Train model
python3 sentiment_classifier.py      # Step 2b: Classify posts
python3 network_analysis.py          # Step 3: Network analysis
python3 network_visualizer.py        # Generate visualizations
python3 final_sentiment_analysis.py  # Step 4: Final report
```

##  Project Structure

```
├── main.py                       # Step 1 orchestrator
├── scraper.py                    # Reddit scraper
├── text_cleaner.py               # 9-step cleaning pipeline
├── create_training_data.py       # Generate training examples
├── sentiment_model.py            # Train sentiment classifier
├── sentiment_classifier.py       # Apply model to dataset
├── network_analysis.py           # Keyword network builder
├── network_visualizer.py         # Generate network graphs
├── final_sentiment_analysis.py   # Comprehensive analysis
├── requirements.txt              # Dependencies
└── visualizations/               # Output graphs
```

##  Output Files

**Data:**
- `raw_scraped_data.json` - Original scraped posts
- `cleaned_data.json` - Cleaned text
- `sentiment_training_data.json` - Training dataset (150 examples)
- `classified_sentiment_data.json` - Posts with sentiment labels

**Models:**
- `sentiment_model.pkl` - Trained classifier
- `vectorizer.pkl` - TF-IDF vectorizer
- `keyword_network.pkl` - Network graph

**Reports:**
- `statistics.json` - Word frequencies
- `network_analysis_results.json` - Network statistics
- Text reports auto-generated by each step

**Visualizations:**
- `visualizations/full_network.png` - Complete keyword network
- `visualizations/communities.png` - Topic communities
- `visualizations/community_*.png` - Individual communities
- `visualizations/sentiment_overview.png` - 4-panel analysis

##  Requirements

- Python 3.9+
- requests
- scikit-learn
- pandas
- numpy
- networkx
- matplotlib

##  Notes

- Uses public Reddit JSON API (no auth needed)
- Includes rate limiting (2s delays)
- Stop words filtered for cleaner network analysis
- All generated reports/data excluded from git

---

**Educational project for analyzing agricultural technology discussions.**
